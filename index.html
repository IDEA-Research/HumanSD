
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation</title>
    <link href="./style.css" rel="stylesheet">
  </head>

  <body>
      <div class="content">
        <h1><strong>
          HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation
        </strong></h1>
        <p id="authors">
          <span><a href=""></a></span>
          <a href="https://juxuan.space" style="pointer-events: none; text-decoration:none; color: black;">Xuan Ju</a><sup style="margin-left: -7px;">12</sup>
          <a href="https://ailingzeng.site/" style="pointer-events: none; text-decoration:none; color: black;">Ailing Zeng</a><sup style="margin-left: -7px;">1</sup>
          <a href="https://zcc31415926.github.io/" style="pointer-events: none; text-decoration:none; color: black;">Chenchen Zhao</a><sup style="margin-left: -7px;">2</sup>
          <a href="https://github.com/wendyjnwang/" style="pointer-events: none; text-decoration:none; color: black;">Jianan Wang</a><sup style="margin-left: -7px;">1</sup>
          <a href="https://www.leizhang.org/" style="pointer-events: none; text-decoration:none; color: black;">Lei Zhang</a><sup style="margin-left: -7px;">1</sup>
          <a href="https://cure-lab.github.io/" style="pointer-events: none; text-decoration:none; color: black;">Qiang Xu</a><sup style="margin-left: -7px;">2</sup>
          <br><br>
          <span style="font-size: 22px;"><sup>1</sup>International Digital Economy Academy</span>
          <!-- <br> -->
          &nbsp;&nbsp;&nbsp;
          <span style="font-size: 22px"><sup>2</sup>The Chinese University of Hong Kong</span>
        </p>
        <br>
        <p style="text-align: center; font-size: 18px;">
          <em>
            HumanSD highlights multi-scenario human-centric image generation with precise pose control, which reaches State-of-the-art performance in terms of pose and image quality.
          </em>
        </p>
        <p style="text-align: center; font-size: 20px;">
          <a href="https://arxiv.org/abs/2304.04269" target="_blank">[Paper]</a>
          &nbsp;&nbsp;&nbsp;
          <a href="https://github.com/IDEA-Research/HumanSD" target="_blank">[Code]</a>
          &nbsp;&nbsp;&nbsp;
          <a href="https://drive.google.com/file/d/1Djc2uJS5fmKnKeBnL34FnAAm3YSH20Bb/view?usp=sharing" target="_blank">[Video]</a>
        </p>
        <br>
        <img src="assets/teaser.png" class="teaser-gif" style="width:100%">
      </div>

      <div class="content">
        <h2 style="text-align: center;">Abstract</h2>
        <p>
          Controllable human image generation (HIG) has numerous real-life applications. 
          State-of-the-art solutions, such as ControlNet and T2I-Adapter, introduce an additional learnable branch on top of the frozen pre-trained stable diffusion (SD) model, which can enforce various conditions, including skeleton guidance of HIG.
          While such a plug-and-play approach is appealing, the inevitable and uncertain conflicts between the original images produced from the frozen SD branch and the given condition incur significant challenges for the learnable branch, which essentially conducts image feature editing for condition enforcement.
        </p>
        <p>
          In this work, we propose a <strong>native</strong> skeleton-guided diffusion model for controllable HIG called <strong>HumanSD</strong>. Instead of performing image editing with dual-branch diffusion, we fine-tune the original SD model using a novel <strong>heatmap-guided denoising loss</strong>. This strategy effectively and efficiently strengthens the given skeleton condition during model training while mitigating the catastrophic forgetting effects. HumanSD is fine-tuned on the assembly of three large-scale human-centric datasets with text-image-pose information, two of which are established in this work. HumanSD outperforms ControlNet
          in terms of accurate pose control and image quality, particularly when the given skeleton guidance is sophisticated.          
        </p>
      </div>

      <div class="content">
        <h2 style="text-align: center;">Video</h2>
        <center>
          <video class="center" src="https://drive.google.com/uc?export=download&id=1Djc2uJS5fmKnKeBnL34FnAAm3YSH20Bb" controls></video>
        </center>
        </div>


      <div class="content">
        <h2>Model Overview</h2>
        <img class="summary-img" src="assets/model.png" style="width:90%;"><br><br>
        <p>
          Overview. (a) shows the proposed framework HumanSD with a novel heatmap-guided denoising loss. (b)
          shows the recent SOTA method, ControlNet, which doubles an SD UNet encoder for condition extraction and freezes
          the original SD branch to maintain image generation ability.
        </p>
      </div>

      <div class="content">
        <h2>Quantitative Results</h2>
        <img class="summary-img" src="assets/quantitative_results.png" style="width:90%;"><br><br>
      </div>

      <div class="content">
        <h2>Qualitative Results</h2>
        <p style="font-size: 18px">
          <strong>Natural Scene</strong>
        </p>
        <img class="summary-img" src="assets/natural1.png" style="width:70%;"><br><br>
        <img class="summary-img" src="assets/natural2.png" style="width:70%;"><br><br>
        <img class="summary-img" src="assets/natural3.png" style="width:70%;"><br><br>
        <img class="summary-img" src="assets/natural4.png" style="width:70%;"><br><br>
        <img class="summary-img" src="assets/natural5.png" style="width:70%;"><br><br>
        <p style="font-size: 18px">
          <strong>Sketch Scene</strong>
        </p>
        <img class="summary-img" src="assets/sketch1.png" style="width:70%;"><br><br>
        <img class="summary-img" src="assets/sketch2.png" style="width:70%;"><br><br>
        <p style="font-size: 18px">
          <strong>Shadow Play Scene</strong>
        </p>       
        <img class="summary-img" src="assets/shadowplay1.png" style="width:70%;"><br><br>
        <p style="font-size: 18px">
          <strong>Children Drawing Scene</strong>
        </p>   
        <img class="summary-img" src="assets/childrendrawing1.png" style="width:70%;"><br><br>
        <p style="font-size: 18px">
          <strong>Oil Painting Scene</strong>
        </p>  
        <img class="summary-img" src="assets/oilpainting1.png" style="width:70%;"><br><br>
        <p style="font-size: 18px">
          <strong>Watercolor Scene</strong>
        </p>  
        <img class="summary-img" src="assets/watercolor1.png" style="width:70%;"><br><br>
        <p style="font-size: 18px">
          <strong>Digital Art Scene</strong>
        </p>  
        <img class="summary-img" src="assets/digitalart1.png" style="width:70%;"><br><br>
        <p style="font-size: 18px">
          <strong>Relief Scene</strong>
        </p>  
        <img class="summary-img" src="assets/relief1.png" style="width:70%;"><br><br>
        <p style="font-size: 18px">
          <strong>Sculpture Scene</strong>
        </p>  
        <img class="summary-img" src="assets/sculpture1.png" style="width:70%;"><br><br>
      </div>


      <div class="content">
        <h2 style="text-align: center;">Contact Us!</h2>
        <p style="font-size: 18px">
          For detailed questions about this work, please contact juxuan.27@gmail.com
          <br>
          We are <font color=red>looking for</font> talented, motivated, and creative <font color=red>research and engineering interns</font> working on human-centric visual understanding and generation topics. If you are interested, please send your CV to Ailing Zeng (zengailing@idea.edu.cn).

        </p>
      </div>

      <div class="content">
        <h2>BibTex</h2>
        <code> @article{ju2023humansd,<br>
        &nbsp;&nbsp;title={Human{SD}: A Native Skeleton-Guided Diffusion Model for Human Image Generation},<br>
        &nbsp;&nbsp;author={Xuan Ju and Ailing Zeng and Chenchen Zhao and Jianan Wang and Lei Zhang and Qiang Xu},<br>
        &nbsp;&nbsp;year={2023},,<br>
        &nbsp;&nbsp;eprint={1904.06539},<br>
        &nbsp;&nbsp;archivePrefix={arXiv},<br>
        &nbsp;&nbsp;primaryClass={cs.CV}<br>
        } <br>
        @inproceedings{ju2023human,<br>
        &nbsp;&nbsp;title={Human-Art: A Versatile Human-Centric Dataset Bridging Natural and Artificial Scenes},<br>
        &nbsp;&nbsp;author={Ju, Xuan and Zeng, Ailing and Wang, Jianan and Xu, Qiang and Zhang, Lei},<br>
        &nbsp;&nbsp;booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},<br>
        &nbsp;&nbsp;year={2023},<br>
        }
      </code> 
      </div>

      <br><br>
      <footer class="footer">
        <div class="container">
          <div class="columns is-centered">
            <!-- <div class="content"> -->
              website template from <a href="https://dreambooth.github.io/">dreambooth</a>
            <!-- </div> -->
          </div>
        </div>
      </footer>
      <br><br>
  </body>
</html>
